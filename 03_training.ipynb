{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "78025c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "import torch\n",
    "import torchvision.transforms as tf\n",
    "import pdb\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d1ab565",
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyNeuralNetwork import NeuralNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af8decd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetDatasets(download=True):\n",
    "    dataset_train = datasets.FashionMNIST(\n",
    "        root = r'data/train',\n",
    "        download = download,\n",
    "        train = True,\n",
    "        transform = tf.ToTensor() \n",
    "    )\n",
    "    \n",
    "    dataset_test = datasets.FashionMNIST(\n",
    "        root = r'data/test',\n",
    "        download = download,\n",
    "        train = False,\n",
    "        transform = tf.ToTensor() \n",
    "    )\n",
    "    return dataset_train, dataset_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b604b987",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train, dataset_test = GetDatasets(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "224e58a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 500\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "dataloader_test = DataLoader(dataset_test, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2ace5f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cpu'\n",
    "network = NeuralNetwork().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "392c1575",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(network.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d4e7f766",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1db8f4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:     0.5, Epoch: 1, Training loss: 12.86, Test accuracy : 10.86%\n",
      "Learning rate:     0.5, Epoch: 2, Training loss: 11.18, Test accuracy : 10.68%\n",
      "Learning rate:     0.5, Epoch: 3, Training loss: 10.74, Test accuracy : 9.93%\n",
      "Learning rate:     0.5, Epoch: 4, Training loss: 10.62, Test accuracy : 9.94%\n",
      "Learning rate:     0.5, Epoch: 5, Training loss: 10.55, Test accuracy : 10.47%\n",
      "Learning rate:     0.5, Epoch: 6, Training loss: 10.51, Test accuracy : 9.97%\n",
      "Learning rate:     0.5, Epoch: 7, Training loss: 10.48, Test accuracy : 10.02%\n",
      "Learning rate:     0.5, Epoch: 8, Training loss: 10.46, Test accuracy : 10.43%\n",
      "Learning rate:     0.5, Epoch: 9, Training loss: 10.43, Test accuracy : 10.65%\n",
      "Learning rate:     0.5, Epoch: 10, Training loss: 10.42, Test accuracy : 10.77%\n",
      "Learning rate:     0.5, Epoch: 11, Training loss: 10.42, Test accuracy : 10.35%\n",
      "Learning rate:     0.5, Epoch: 12, Training loss: 10.39, Test accuracy : 10.18%\n",
      "Learning rate:     0.5, Epoch: 13, Training loss: 10.39, Test accuracy : 10.64%\n",
      "Learning rate:     0.5, Epoch: 14, Training loss: 10.38, Test accuracy : 10.92%\n",
      "Learning rate:     0.5, Epoch: 15, Training loss: 10.37, Test accuracy : 10.45%\n",
      "Learning rate:     0.5, Epoch: 16, Training loss: 10.36, Test accuracy : 10.09%\n",
      "Learning rate:     0.5, Epoch: 17, Training loss: 10.35, Test accuracy : 10.24%\n",
      "Learning rate:     0.5, Epoch: 18, Training loss: 10.34, Test accuracy : 11.08%\n",
      "Learning rate:     0.5, Epoch: 19, Training loss: 10.34, Test accuracy : 10.49%\n",
      "Learning rate:     0.5, Epoch: 20, Training loss: 10.33, Test accuracy : 10.26%\n",
      "Learning rate:     0.5, Epoch: 21, Training loss: 10.32, Test accuracy : 10.66%\n",
      "Learning rate:     0.5, Epoch: 22, Training loss: 10.31, Test accuracy : 10.14%\n",
      "Learning rate:     0.5, Epoch: 23, Training loss: 10.31, Test accuracy : 10.78%\n",
      "Learning rate:     0.5, Epoch: 24, Training loss: 10.30, Test accuracy : 10.31%\n",
      "Learning rate:     0.5, Epoch: 25, Training loss: 10.30, Test accuracy : 10.14%\n",
      "Learning rate:    0.05, Epoch: 1, Training loss: 10.26, Test accuracy : 10.26%\n",
      "Learning rate:    0.05, Epoch: 2, Training loss: 10.26, Test accuracy : 10.79%\n",
      "Learning rate:    0.05, Epoch: 3, Training loss: 10.26, Test accuracy : 10.49%\n",
      "Learning rate:    0.05, Epoch: 4, Training loss: 10.26, Test accuracy : 10.88%\n",
      "Learning rate:    0.05, Epoch: 5, Training loss: 10.25, Test accuracy : 11.11%\n",
      "Learning rate:    0.05, Epoch: 6, Training loss: 10.25, Test accuracy : 10.18%\n",
      "Learning rate:    0.05, Epoch: 7, Training loss: 10.25, Test accuracy : 9.78%\n",
      "Learning rate:    0.05, Epoch: 8, Training loss: 10.25, Test accuracy : 10.56%\n",
      "Learning rate:    0.05, Epoch: 9, Training loss: 10.25, Test accuracy : 9.91%\n",
      "Learning rate:    0.05, Epoch: 10, Training loss: 10.25, Test accuracy : 10.16%\n",
      "Learning rate:    0.05, Epoch: 11, Training loss: 10.25, Test accuracy : 10.23%\n",
      "Learning rate:    0.05, Epoch: 12, Training loss: 10.25, Test accuracy : 10.51%\n",
      "Learning rate:    0.05, Epoch: 13, Training loss: 10.25, Test accuracy : 10.42%\n",
      "Learning rate:    0.05, Epoch: 14, Training loss: 10.25, Test accuracy : 10.15%\n",
      "Learning rate:    0.05, Epoch: 15, Training loss: 10.25, Test accuracy : 10.48%\n",
      "Learning rate:    0.05, Epoch: 16, Training loss: 10.25, Test accuracy : 10.55%\n",
      "Learning rate:    0.05, Epoch: 17, Training loss: 10.24, Test accuracy : 10.34%\n",
      "Learning rate:    0.05, Epoch: 18, Training loss: 10.24, Test accuracy : 10.32%\n",
      "Learning rate:    0.05, Epoch: 19, Training loss: 10.24, Test accuracy : 10.53%\n",
      "Learning rate:    0.05, Epoch: 20, Training loss: 10.24, Test accuracy : 11.09%\n",
      "Learning rate:    0.05, Epoch: 21, Training loss: 10.24, Test accuracy : 10.15%\n",
      "Learning rate:    0.05, Epoch: 22, Training loss: 10.24, Test accuracy : 9.86%\n",
      "Learning rate:    0.05, Epoch: 23, Training loss: 10.24, Test accuracy : 10.94%\n",
      "Learning rate:    0.05, Epoch: 24, Training loss: 10.24, Test accuracy : 10.48%\n",
      "Learning rate:    0.05, Epoch: 25, Training loss: 10.24, Test accuracy : 10.55%\n",
      "Learning rate:   0.005, Epoch: 1, Training loss: 10.24, Test accuracy : 10.44%\n",
      "Learning rate:   0.005, Epoch: 2, Training loss: 10.24, Test accuracy : 10.93%\n",
      "Learning rate:   0.005, Epoch: 3, Training loss: 10.24, Test accuracy : 10.12%\n",
      "Learning rate:   0.005, Epoch: 4, Training loss: 10.24, Test accuracy : 10.63%\n",
      "Learning rate:   0.005, Epoch: 5, Training loss: 10.24, Test accuracy : 10.65%\n",
      "Learning rate:   0.005, Epoch: 6, Training loss: 10.24, Test accuracy : 10.28%\n",
      "Learning rate:   0.005, Epoch: 7, Training loss: 10.24, Test accuracy : 9.95%\n",
      "Learning rate:   0.005, Epoch: 8, Training loss: 10.24, Test accuracy : 10.51%\n",
      "Learning rate:   0.005, Epoch: 9, Training loss: 10.24, Test accuracy : 10.69%\n",
      "Learning rate:   0.005, Epoch: 10, Training loss: 10.24, Test accuracy : 10.37%\n",
      "Learning rate:   0.005, Epoch: 11, Training loss: 10.24, Test accuracy : 9.91%\n",
      "Learning rate:   0.005, Epoch: 12, Training loss: 10.24, Test accuracy : 10.31%\n",
      "Learning rate:   0.005, Epoch: 13, Training loss: 10.24, Test accuracy : 11.37%\n",
      "Learning rate:   0.005, Epoch: 14, Training loss: 10.24, Test accuracy : 10.86%\n",
      "Learning rate:   0.005, Epoch: 15, Training loss: 10.24, Test accuracy : 10.74%\n",
      "Learning rate:   0.005, Epoch: 16, Training loss: 10.24, Test accuracy : 10.09%\n",
      "Learning rate:   0.005, Epoch: 17, Training loss: 10.24, Test accuracy : 10.39%\n",
      "Learning rate:   0.005, Epoch: 18, Training loss: 10.24, Test accuracy : 10.56%\n",
      "Learning rate:   0.005, Epoch: 19, Training loss: 10.24, Test accuracy : 10.97%\n",
      "Learning rate:   0.005, Epoch: 20, Training loss: 10.24, Test accuracy : 10.76%\n",
      "Learning rate:   0.005, Epoch: 21, Training loss: 10.24, Test accuracy : 10.12%\n",
      "Learning rate:   0.005, Epoch: 22, Training loss: 10.24, Test accuracy : 10.58%\n",
      "Learning rate:   0.005, Epoch: 23, Training loss: 10.24, Test accuracy : 10.96%\n",
      "Learning rate:   0.005, Epoch: 24, Training loss: 10.23, Test accuracy : 10.11%\n",
      "Learning rate:   0.005, Epoch: 25, Training loss: 10.23, Test accuracy : 10.85%\n",
      "Learning rate:  0.0005, Epoch: 1, Training loss: 10.23, Test accuracy : 11.20%\n",
      "Learning rate:  0.0005, Epoch: 2, Training loss: 10.23, Test accuracy : 10.65%\n",
      "Learning rate:  0.0005, Epoch: 3, Training loss: 10.23, Test accuracy : 10.73%\n",
      "Learning rate:  0.0005, Epoch: 4, Training loss: 10.23, Test accuracy : 10.46%\n",
      "Learning rate:  0.0005, Epoch: 5, Training loss: 10.23, Test accuracy : 10.88%\n",
      "Learning rate:  0.0005, Epoch: 6, Training loss: 10.23, Test accuracy : 10.74%\n",
      "Learning rate:  0.0005, Epoch: 7, Training loss: 10.23, Test accuracy : 11.23%\n",
      "Learning rate:  0.0005, Epoch: 8, Training loss: 10.23, Test accuracy : 10.47%\n",
      "Learning rate:  0.0005, Epoch: 9, Training loss: 10.23, Test accuracy : 9.89%\n",
      "Learning rate:  0.0005, Epoch: 10, Training loss: 10.23, Test accuracy : 10.31%\n",
      "Learning rate:  0.0005, Epoch: 11, Training loss: 10.23, Test accuracy : 11.00%\n",
      "Learning rate:  0.0005, Epoch: 12, Training loss: 10.23, Test accuracy : 10.46%\n",
      "Learning rate:  0.0005, Epoch: 13, Training loss: 10.23, Test accuracy : 10.76%\n",
      "Learning rate:  0.0005, Epoch: 14, Training loss: 10.23, Test accuracy : 10.37%\n",
      "Learning rate:  0.0005, Epoch: 15, Training loss: 10.23, Test accuracy : 10.28%\n",
      "Learning rate:  0.0005, Epoch: 16, Training loss: 10.23, Test accuracy : 10.25%\n",
      "Learning rate:  0.0005, Epoch: 17, Training loss: 10.23, Test accuracy : 10.23%\n",
      "Learning rate:  0.0005, Epoch: 18, Training loss: 10.23, Test accuracy : 10.72%\n",
      "Learning rate:  0.0005, Epoch: 19, Training loss: 10.23, Test accuracy : 10.93%\n",
      "Learning rate:  0.0005, Epoch: 20, Training loss: 10.23, Test accuracy : 10.21%\n",
      "Learning rate:  0.0005, Epoch: 21, Training loss: 10.23, Test accuracy : 10.32%\n",
      "Learning rate:  0.0005, Epoch: 22, Training loss: 10.23, Test accuracy : 10.91%\n",
      "Learning rate:  0.0005, Epoch: 23, Training loss: 10.23, Test accuracy : 10.84%\n",
      "Learning rate:  0.0005, Epoch: 24, Training loss: 10.23, Test accuracy : 10.45%\n",
      "Learning rate:  0.0005, Epoch: 25, Training loss: 10.23, Test accuracy : 10.78%\n"
     ]
    }
   ],
   "source": [
    "for lr in [0.5, 0.05, 0.005, 0.0005]:\n",
    "    optimizer = torch.optim.SGD(network.parameters(), lr=lr)\n",
    "    \n",
    "    log_dir = './logs/{}'.format(lr)\n",
    "    writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        \n",
    "        epoch_loss = 0\n",
    "        epoch_accuracy = 0\n",
    "        \n",
    "        for idx, batch in enumerate(dataloader_train):\n",
    "            # zero the gradient\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            x, y = batch[0], batch[1]\n",
    "\n",
    "            # flatten it first\n",
    "            x = torch.flatten(x, start_dim=1)\n",
    "\n",
    "            # forward pass\n",
    "            predictions = network(x)\n",
    "\n",
    "            loss = criterion(predictions, y)\n",
    "\n",
    "            # backpropogate the loss\n",
    "            loss.backward()\n",
    "\n",
    "            # step the optimizer in the direction of the gradient\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "        # evaluate prediction accuracy in test set\n",
    "        for idx, batch in enumerate(dataloader_test):\n",
    "            network.eval()\n",
    "            \n",
    "            x, y = batch[0], batch[1]\n",
    "            x = torch.flatten(x, start_dim=1)\n",
    "            predcitions = network(x)\n",
    "            \n",
    "            pred_label = torch.argmax(predictions, dim=1)\n",
    "            n_correct = (y==pred_label).float()\n",
    "            accuracy = n_correct.sum() / n_correct.numel()\n",
    "            epoch_accuracy += 100 * accuracy\n",
    "            \n",
    "        # tensorboard \n",
    "        writer.add_scalar('Epoch loss', epoch_loss / idx, epoch)\n",
    "        writer.add_scalar('Epoch accuracy', epoch_accuracy / idx, epoch)\n",
    "        writer.flush()\n",
    "        \n",
    "        print('Learning rate: {:>7}, Epoch: {}, Training loss: {:.2f}, Test accuracy : {:.2f}%'.format(\n",
    "            lr, epoch + 1, epoch_loss / idx, epoch_accuracy / idx))\n",
    "        writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c8c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#% tensorboard --logdir=logs --host=127.0.0.1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

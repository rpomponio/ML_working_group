{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e72febd",
   "metadata": {},
   "source": [
    "# Make sure to run this in the `my-torch` environment!\n",
    "\n",
    "Link to tutorial: https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html\n",
    "\n",
    "> Every module in PyTorch subclasses the `nn.Module`. A neural network is a module itself that consists of other modules (layers). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ed8526e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "394b41e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0f86824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU not available, therfore use CPU\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ae0280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a neural network by sub-classing nn.Module \n",
    "# define initialization and `forward` method\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = nn.Flatten() ## what does this do?\n",
    "        # the following stack combines two linear layers with ReLU activation\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(in_features=28 * 28, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_features=512, out_features=10)\n",
    "        )\n",
    "    \n",
    "    # define feed-forward operation\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x) ## flattens input into a vector sized 784\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3cc8f28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = NeuralNetwork().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e12ed010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create random Tensor and run a single forward operation\n",
    "X = torch.rand(1, 28, 28, device=device)\n",
    "logits = model(X)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c50742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0922, 0.0944, 0.1081, 0.1037, 0.1067, 0.0955, 0.1010, 0.0944, 0.1050,\n",
       "         0.0991]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert Tensor output into probabilities with Softmax\n",
    "probs = nn.Softmax(dim=1)(logits)\n",
    "y_pred = probs.argmax(1)[0]\n",
    "pr_pred = float(probs[0, y_pred])\n",
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e20ef92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class: 2, with probability: 0.108\n"
     ]
    }
   ],
   "source": [
    "print('Predicted class: {} with probability: {:.3}'.format(y_pred, pr_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4481f623",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 28, 28])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input will be 28 x 28 pixels, create minibatch of 3 images\n",
    "img_minibtch = torch.rand(3, 28, 28)\n",
    "img_minibtch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b4f9b5ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# flatten the minibatch (preserves one dimension for separate samples)\n",
    "flt_minibtch = nn.Flatten()(img_minibtch)\n",
    "flt_minibtch.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43308fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply the first (hidden) linear layer\n",
    "layer1 = nn.Linear(in_features=28*28, out_features=512)\n",
    "hidden1 = layer1(flt_minibtch)\n",
    "hidden1.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "954fef68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before ReLU tensor([[ 0.1254,  0.0970, -0.0260,  ...,  0.4807, -0.4991,  0.1651],\n",
      "        [ 0.0687,  0.0592,  0.2136,  ...,  0.0374, -0.3441,  0.1987],\n",
      "        [ 0.3345,  0.1573,  0.2000,  ...,  0.3032, -0.3836,  0.5333]],\n",
      "       grad_fn=<AddmmBackward0>)\n",
      "After ReLU tensor([[0.1254, 0.0970, 0.0000,  ..., 0.4807, 0.0000, 0.1651],\n",
      "        [0.0687, 0.0592, 0.2136,  ..., 0.0374, 0.0000, 0.1987],\n",
      "        [0.3345, 0.1573, 0.2000,  ..., 0.3032, 0.0000, 0.5333]],\n",
      "       grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# apply activation layer\n",
    "print('Before ReLU:', hidden1)\n",
    "hidden1 = nn.ReLU()(hidden1)\n",
    "print('After ReLU:', hidden1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c6368f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: linear_relu_stack.0.weight | Size: torch.Size([512, 784]) | Values : tensor([[ 0.0294,  0.0215,  0.0137,  ...,  0.0002,  0.0307,  0.0027],\n",
      "        [ 0.0347,  0.0249, -0.0086,  ..., -0.0062, -0.0187,  0.0274]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.0.bias | Size: torch.Size([512]) | Values : tensor([-0.0162,  0.0111], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.weight | Size: torch.Size([512, 512]) | Values : tensor([[ 0.0018, -0.0204,  0.0108,  ..., -0.0215,  0.0072,  0.0230],\n",
      "        [-0.0115, -0.0085,  0.0037,  ..., -0.0107,  0.0220, -0.0070]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.2.bias | Size: torch.Size([512]) | Values : tensor([-0.0151, -0.0304], grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.weight | Size: torch.Size([10, 512]) | Values : tensor([[-0.0024,  0.0107,  0.0299,  ..., -0.0331, -0.0329, -0.0025],\n",
      "        [-0.0048, -0.0065, -0.0404,  ..., -0.0031, -0.0062, -0.0370]],\n",
      "       grad_fn=<SliceBackward0>) \n",
      "\n",
      "Layer: linear_relu_stack.4.bias | Size: torch.Size([10]) | Values : tensor([ 0.0183, -0.0360], grad_fn=<SliceBackward0>) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# zooming out, examine all model parameters\n",
    "for name, param in model.named_parameters():\n",
    "    print('Layer: {} | Size: {} | Values : {} \\n'.format(name, param.size(), param[:2]))\n",
    "          \n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "be865f26",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 784])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer1.weight.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be99a31c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
